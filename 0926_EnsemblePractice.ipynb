{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCu72vDHGMHo"
   },
   "source": [
    "## **| 앙상블 학습과 랜덤 포레스트 연습 문제**\n",
    "___\n",
    "- 출처 : 핸즈온 머신러닝 Ch07 앙상블 학습과 랜덤 포레스트 연습문제 2, 7, 8, 9번\n",
    "- 이론적 지식을 묻는 문제의 경우 텍스트 셀을 추가하여 정답을 적어주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hQLO-M61qSVA"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ifUj-jvi5NE"
   },
   "source": [
    "### **1. 직접 투표와 간접 투표 분류기 사이의 차이점은 무엇일까요?**\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 직접 투표 분류기 (hard voting) : 각 분류기의 예측을 모아 가장 많이 선택된 클래스 예측\n",
    "- 간접 투표 분류기 (soft voting) : 모든 분류기가 클래스의 확률을 예측할 수 있으면 (predict_proba() 메서드가 존재), 개별 분류기의 예측을 평균내어 확률이 가장 높은 클래스를 예측\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JK-WcK3ujU0E"
   },
   "source": [
    "### **2. 그레디언트 부스팅 앙상블이 훈련 데이터에 과대 적합되었다면 학습률을 어떻게 해야 할까요?**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습률을 0.1처럼 너무 낮춰 트리가 너무 많으면 훈련세트에 과대적합되며, 학습률을 좀더 키우고 점차적으로 작아지도록 설정해야함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3g-_Dq9GiuT"
   },
   "source": [
    "### **3. [실습] 다음 지시에 따라 투표 기반 분류 모델을 만들어 보세요**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aLghZCVj34L"
   },
   "source": [
    "#### **STEP 1. MNIST 데이터를 불러들이고, 훈련, 검증, 테스트 데이터로 나누세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "188lZyYEGJZ7"
   },
   "outputs": [],
   "source": [
    "# import MNIST dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame = False)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lXF4M2MdIpKa"
   },
   "outputs": [],
   "source": [
    "# train/valid/test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHOTxVK3kjnM"
   },
   "source": [
    "####  **STEP 2. 랜덤 포레스트 분류기, 엑스트라 트리 분류기, SVM 분류기, MLP 분류기를 훈련시키세요.**\n",
    "- 모델 파라미터는 `n_estimators=100`, `random_state=42`로 설정합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "udX8yKD4k9DE"
   },
   "outputs": [],
   "source": [
    "# import package\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iEG8FFJ1lBw4"
   },
   "outputs": [],
   "source": [
    "# model fitting\n",
    "rf_clf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "ext_clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = LinearSVC(max_iter=10000, random_state=42)\n",
    "mlp_clf = MLPClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lB4OagE2lglK"
   },
   "source": [
    "####  **STEP 3-1. 앞에서 훈련시킨 각 모델을 직접 투표 방법을 사용해 앙상블로 연결하고 훈련시킨 후, `score()`메서드를 이용하여 검증 데이터셋에서의 성능을 평가해보세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LTnt0h4Hmitr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaewon/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('ext', ExtraTreesClassifier(random_state=42)),\n",
       "                             ('svm',\n",
       "                              LinearSVC(max_iter=10000, random_state=42)),\n",
       "                             ('mlp', MLPClassifier(random_state=42))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model fitting\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "models = [('rf',rf_clf), ('ext',ext_clf), ('svm',svm_clf), ('mlp',mlp_clf)]\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=models, voting='hard')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6M8p66FHmt0U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model test\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = voting_clf.predict(X_val)\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgmsaye3oLYQ"
   },
   "source": [
    "####  **STEP 3-2. 검증 데이터셋에서 각 분류 모델의 성능을 `score()` 메서드를 이용하여 확인해보고, 가장 성능이 낮은 모델을 제거하여 그 결과를 비교해보세요.**\n",
    "- Hint : 가장 성능이 낮은 모델을 제거할 때 `set_params`를 활용해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-Ykw6-_4rV9S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaewon/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 분류 모델 학습\n",
    "rf_clf.fit(X_train, y_train)\n",
    "ext_clf.fit(X_train, y_train)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ghPFb287om1Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.9647238095238095\n",
      "ExtraTreesClassifier 0.9674666666666667\n",
      "LinearSVC 0.8568380952380953\n",
      "MLPClassifier 0.9590095238095238\n"
     ]
    }
   ],
   "source": [
    "# 각 분류 모델의 성능 확인\n",
    "for clf in (rf_clf, ext_clf, svm_clf, mlp_clf):\n",
    "    y_pred = clf.predict(X_val)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN-HIeWhosGs"
   },
   "source": [
    "- Q. 어떤 모델의 성능이 가장 낮나요?\n",
    "- A. LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "shHFXdWcoqf6"
   },
   "outputs": [],
   "source": [
    "# 가장 성능이 낮은 모델 제거\n",
    "del models[2]\n",
    "voting_clf2 = VotingClassifier(estimators=models, voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PpV5S__I2U3F",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('ext', ExtraTreesClassifier(random_state=42)),\n",
       "                             ('mlp', MLPClassifier(random_state=42))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model fitting\n",
    "voting_clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "BMTkSkbNpRQi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9702857142857143"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 제거 후 성능 확인\n",
    "y_pred = voting_clf2.predict(X_val)\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pDjW5XcHPOt"
   },
   "source": [
    "### **4. 다음 단계를 따라 앞에서 훈련시킨 분류 모델들을 이용하여 스태킹 앙상블을 구성해보자.**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xhEB_KtH47q"
   },
   "source": [
    "#### **STEP 1. 3번 문제의 각 분류 모델을 실행해서 검증 세트에서 예측을 만들고, 그 결과로 훈련 세트를 만들어 보세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "3CLxYCROIAk6"
   },
   "outputs": [],
   "source": [
    "rf_pred = rf_clf.predict(X_val)\n",
    "ext_pred = ext_clf.predict(X_val)\n",
    "svm_pred = svm_clf.predict(X_val)\n",
    "mlp_pred = mlp_clf.predict(X_val)\n",
    "\n",
    "pred = np.array([rf_pred, ext_pred, svm_pred, mlp_pred])\n",
    "pred = np.transpose(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHgSqi-zIBCd"
   },
   "source": [
    "####  **STEP 2. 새로운 훈련 세트를 이용하여 랜덤 포레스트 분류 모델을 학습시켜 보세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "SsBT_d0MIH-V"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf_blender = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "rf_clf_blender.fit(pred, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43MJatnzquTH"
   },
   "source": [
    "- 이 랜덤 포레스트 분류 모델이 바로 블렌더에 해당합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWozt0n2IJZL"
   },
   "source": [
    "####  **STEP 3. 이제 테스트셋에서 스태킹 앙상블 모델을 평가해보세요.**\n",
    "- 성능 평가 지표로 **정확도**를 이용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Yo4H-hTRIW7-"
   },
   "outputs": [],
   "source": [
    "# 각 분류 모델의 예측을 만들어 새로운 데이터셋 생성\n",
    "rf_pred_t = rf_clf.predict(X_test)\n",
    "ext_pred_t = ext_clf.predict(X_test)\n",
    "svm_pred_t = svm_clf.predict(X_test)\n",
    "mlp_pred_t = mlp_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "fVdwwmSYKDmF"
   },
   "outputs": [],
   "source": [
    "# 새로운 데이터셋을 이용하여 블렌더로 예측\n",
    "pred_t = np.array([rf_pred_t, ext_pred_t, svm_pred_t, mlp_pred_t])\n",
    "pred_t = np.transpose(pred_t)\n",
    "\n",
    "y_pred = rf_clf_blender.predict(pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ijlm1VbOKFSN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9669714285714286"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model test\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
